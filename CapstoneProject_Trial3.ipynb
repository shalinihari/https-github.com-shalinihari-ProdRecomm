{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkGpzaCnwojX"
   },
   "source": [
    "# Capstone Project : Sentiment Based Product Recommendation System**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T09YAa82w4f9"
   },
   "source": [
    "## Project Statement\n",
    "### Ebuss is a e-commerce company which has captured huge market in different fields like household essentials, books, personal care products, medicines, cosmetic items, beauty products, electrical appliances, kitchen and dining products and health care products.\n",
    "### We need to build a model that will improve the recommendations given to the users given their past reviews and ratings.\n",
    "## Result Expected\n",
    "    - Feature extraction\n",
    "    - Training a text classification model\n",
    "    - Building a recommendation system in User-based and Item-based recommendation system\n",
    "    - Deployment the project with a user interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qu7yckLQw8gr"
   },
   "source": [
    "### Few Data Dictionary reference\n",
    "    - id:\tUniques identity number to identify each unique review given by the user to a particular product in                             the dataset\n",
    "    - brand: Name of the brand of the product to which user has given review and rating\n",
    "    - categories:\tCategory of the product like household essentials, books, personal care products, medicines,                                   cosmeticÂ items, beauty products, electrical appliances, kitchen and dining products, health care                               products and many more.\n",
    "    - manufacturer:\tName of the manufacturer of the product\n",
    "    - name:\tName of the product to which user has added review or rating\n",
    "    - reviews_date:\tDate on which the review has been added by the user\n",
    "    - reviews_didPurchase:\tWhether a particular user has purchased the product or not\n",
    "    - reviews_doRecommend:\tWhether a particular user has recommended the product or not\n",
    "    - reviews_rating:\tRating given by the user to a particular product\n",
    "    - reviews_text:\tReview given by the user to a particular product\n",
    "    - reviews_title:\tThe title of the review given by the user to a particular product\n",
    "    - reviews_userCity:\tThe residing city of the user\n",
    "    - reviews_userProvince: The residing province of the user\n",
    "    - reviews_username:\tThe unique identification for individual user in the dataset\n",
    "    - user_sentiment:\tThe overall sentiment of the user for a particular product (Positive or Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCVruI7Wxm9v"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHaZdKwpwvwq"
   },
   "outputs": [],
   "source": [
    "# To remove Warnings, adding the below libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-wgad0JxpKR"
   },
   "outputs": [],
   "source": [
    "### Importing Pandas librries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Importing the libraries for visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlAgFLVIxq5a",
    "outputId": "1ea5a897-671b-44ef-d989-d91104982476"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQfPMtBIxtSf"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy import *\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWl3tRNpxvtg"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bR5s9Tgix2R0"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCo6Y7IL39lD"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuopqQaV0VT6"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oxn_FZpS3y3i"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfnNfCjDx6JY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1_zuVPRx8KM"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EsDEPdoP2rT"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "from sklearn.metrics import precision_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI_1lH2s_HMa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "from sklearn.metrics import precision_score,f1_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5LhA97Wx9iT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report,precision_score,recall_score,confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efvkYIqxx_qZ"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8u0elulyCEM"
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Be0qS1diYDT0"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the data file into df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "KnSukpOjyJn_",
    "outputId": "b3a4cd8b-85f3-48e7-8e5b-f77cccc2c444"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample30.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8lbAgWjyZHC",
    "outputId": "aa533cc0-51d1-43f0-fde2-6f824fb9ba08"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are total of 30K records and 15 columns. Lets Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGhVqQPizNnJ",
    "outputId": "7da31a8e-c89f-4c50-924c-28ee39b62cbf"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see null columns in the data, Lets analyse each column one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxb0OX8qzP_4",
    "outputId": "8b1b052a-6f82-4891-adb8-b0fd7631494d"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMtCUKYrzUxk",
    "outputId": "292ee231-81cb-48a6-ada4-f485b1a42241"
   },
   "outputs": [],
   "source": [
    "(df['reviews_userProvince'].isnull().sum()/df['reviews_rating'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKhq12BYzaqv",
    "outputId": "fb31785c-f732-41c0-f1e8-0386da86ce28"
   },
   "outputs": [],
   "source": [
    "(df['reviews_userCity'].isnull().sum()/df['reviews_rating'].count())*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7paYvoGzfIF"
   },
   "source": [
    "- We can see more than 90% null values in 'reviews_userProvince' and 'reviews_userCity' columns. These columns doesnt have useful information for the analysis. So deleting both the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E63oZLlXzcZd"
   },
   "outputs": [],
   "source": [
    "df.drop(['reviews_userCity','reviews_userProvince'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqIAqBGRzl6o",
    "outputId": "9c4e98d5-05a7-4c21-e4d9-b88dfaae4367"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqWavobvzoVU",
    "outputId": "81263f8b-ae42-4943-8fbe-b1ae2f4333a3"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uytOII9az5BT",
    "outputId": "e4a60ece-ca3e-4941-ad97-b8cd948ea015"
   },
   "outputs": [],
   "source": [
    "# Lets check the number of users we have\n",
    "df['reviews_username'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6r740cLaz-cz",
    "outputId": "2eaabe4e-bfab-4834-f91a-5ebf739ec6ac"
   },
   "outputs": [],
   "source": [
    "# The unique products provided for analysis\n",
    "df['name'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTCYzRoJ0BGX",
    "outputId": "5b3350fc-3d4d-4597-ee29-bc166ebbe673"
   },
   "outputs": [],
   "source": [
    "df = df[~(df.reviews_username.isnull())]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without username, we cannot perform our analysis. If we label it as something, then the recommendation would not be proper. so we will remove the rows which doesnt have username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9D5mzFrB1NmB",
    "outputId": "ea9d27a3-38f9-4a6d-e876-3ea655cd17f5"
   },
   "outputs": [],
   "source": [
    "df[df['reviews_rating'].isin([3,4,5]) & (df['user_sentiment'].isin(['Negative']))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XjxgO_A4Bic",
    "outputId": "fc06fcb2-d647-42d8-8ca3-a1d5d415343a"
   },
   "outputs": [],
   "source": [
    "df[df['reviews_rating'].isin([1,2]) & (df['user_sentiment'].isin(['Positive']))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the reviews_rating and the user sentiment is not matching. We will bring it match with each other. When read the data manually understood that the review rating and review text are matching, hence, we will change the user sentiment accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3n5UqU7h4Fgx",
    "outputId": "ec8bd705-039e-4cef-fb7e-fe46ad236857"
   },
   "outputs": [],
   "source": [
    "df['user_sentiment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "RC5SzVV44JO-",
    "outputId": "141b1723-e2fd-4504-958a-ddb1df794115"
   },
   "outputs": [],
   "source": [
    "df[df['user_sentiment'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One user sentiment is null, As per our previous decision we will change the user sentiment as per the review rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEJ16PcS5I1u"
   },
   "outputs": [],
   "source": [
    "df.loc[df['reviews_rating'].isin([3,4,5]), ('user_sentiment')] = 'Positive'\n",
    "df.loc[df['reviews_rating'].isin([1,2]), ('user_sentiment')] = 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHSXkGUn--Lz",
    "outputId": "d25245e5-db95-4dac-b324-14a3a4c69d40"
   },
   "outputs": [],
   "source": [
    "df[df['reviews_rating'].isin([3,4,5]) & (df['user_sentiment'].isin(['Negative']))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_IDoGMk_IPn",
    "outputId": "350cacc1-4951-4e87-b9dd-1a1df4c3f2ff"
   },
   "outputs": [],
   "source": [
    "df['user_sentiment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Sentiment null is cleared. Now Lets check other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PANfSpU8_8jU",
    "outputId": "6729c8cc-6416-4eea-ec7c-0ca160057aab"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More null values are in the 'reviews_didPurchase' column. Lets analyse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vU8vaEhzGOx7",
    "outputId": "e7b3e2da-6555-47c2-c109-16c3e479a620"
   },
   "outputs": [],
   "source": [
    "(df['reviews_didPurchase'].isnull().sum()/df['reviews_didPurchase'].count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- About 87% of records are null. Lets see other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufGL3U48BMch",
    "outputId": "64591e27-10d5-4862-c676-b97d124e7af9"
   },
   "outputs": [],
   "source": [
    "df['reviews_didPurchase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "OigbnqTZDFHm",
    "outputId": "b237eabf-6837-4cdb-b673-7ac955c135b8"
   },
   "outputs": [],
   "source": [
    "df.reviews_didPurchase.value_counts().plot.bar()\n",
    "plt.xticks(size=12,rotation = 45)\n",
    "plt.xlabel('Reviewed Purchase',size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel('count', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jz-uH2IZCERQ",
    "outputId": "8988ae31-19ec-4412-a784-e3253c3556d2"
   },
   "outputs": [],
   "source": [
    "df[(df['reviews_didPurchase']==False)]['reviews_rating'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "xZT05WZMDPMY",
    "outputId": "a80fc711-a6c2-45f6-855e-0dfd64192c05"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "graph = sns.countplot(data=df,x='reviews_rating',hue='reviews_didPurchase')\n",
    "plt.title('reviews_didPurchase and reviews_rating')\n",
    "for p in graph.patches:\n",
    "        graph.annotate('{:.2f}'.format(100 * p.get_height()/len(df)), (p.get_x()+ p.get_width() / 2 - 0.05, p.get_y() + p.get_height()),\n",
    "                    color= 'black')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df[(df['reviews_didPurchase']==False)]['reviews_rating'].value_counts().sort_index(ascending=True).plot.bar()\n",
    "plt.xticks(size=12,rotation = 45)\n",
    "plt.xlabel('Reviewer Rating when not purchased',size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel('count', size=12)\n",
    "plt.title('reviews_didPurchase as false and reviews_rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhDRIt_DCdPS",
    "outputId": "1f57ea7f-7dc1-47e8-9afb-3d7a599407c1"
   },
   "outputs": [],
   "source": [
    "df[(df['reviews_didPurchase']==False)]['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "sNokjpfnFjsI",
    "outputId": "61861e74-7b8e-43b3-e218-be163ae60a62"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "graph = sns.countplot(data=df,x='reviews_didPurchase',hue='user_sentiment')\n",
    "plt.title('reviews_didPurchase and user_sentiment')\n",
    "for p in graph.patches:\n",
    "        graph.annotate('{:.2f}'.format(100 * p.get_height()/len(df)), (p.get_x()+ p.get_width() / 2 - 0.05, p.get_y() + p.get_height()),\n",
    "                    color= 'black')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df[(df['reviews_didPurchase']==False)]['user_sentiment'].value_counts().plot.bar()\n",
    "plt.xticks(size=12,rotation = 45)\n",
    "plt.xlabel('User Sentiment when not purchased',size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel('count', size=12)\n",
    "plt.title('reviews_didPurchase False and the user_sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcyGig-JChg2",
    "outputId": "225d7528-598e-4a6d-f2a2-d0a3eb8f70af"
   },
   "outputs": [],
   "source": [
    "df[(df['reviews_didPurchase']==False)]['reviews_doRecommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "zKRkvrLsCjRy",
    "outputId": "c7ce378e-f678-4ab3-bc31-442065256498"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "graph = sns.countplot(data=df,x='reviews_doRecommend',hue='reviews_didPurchase')\n",
    "plt.title('reviews_didPurchase and reviews_doRecommend')\n",
    "for p in graph.patches:\n",
    "        graph.annotate('{:.2f}'.format(100 * p.get_height()/len(df)), (p.get_x()+ p.get_width() / 2 - 0.05, p.get_y() + p.get_height()),\n",
    "                    color= 'black')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df[(df['reviews_didPurchase']==False)]['reviews_doRecommend'].value_counts().plot.bar()\n",
    "plt.xticks(size=12,rotation = 45)\n",
    "plt.xlabel('User Recommendation when not purchased',size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel('count', size=12)\n",
    "plt.title('User Recommendation when not purchased')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNRhMkBBHTL_"
   },
   "source": [
    "Based on the above understanding, the user purchase is not related to any of the other details like Product recommendation, Sentiment and rating. Hence removing the 'reviews_didPurchase' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXC8gbDIE5Q8"
   },
   "outputs": [],
   "source": [
    "df.drop(['reviews_didPurchase'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWnS2yWCIDCP",
    "outputId": "4fe8376d-2fc4-4279-954c-c3c856a5b690"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0CECvsxIH2A",
    "outputId": "b089685c-5d3e-4f6e-c14d-389a2bcc59bb"
   },
   "outputs": [],
   "source": [
    "(df['reviews_doRecommend'].isnull().sum()/df['reviews_doRecommend'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbDe5hgCI9K6",
    "outputId": "1f441d46-7f88-4739-bec4-9d41487effc0"
   },
   "outputs": [],
   "source": [
    "df['reviews_doRecommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "WZ4x6K-lJDr_",
    "outputId": "e97fd370-ff55-4041-f69c-71cd1eda6cc1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "graph = sns.countplot(data=df,x='reviews_rating',hue='reviews_doRecommend')\n",
    "plt.title('reviews_rating and reviews_doRecommend')\n",
    "for p in graph.patches:\n",
    "        graph.annotate('{:.2f}'.format(100 * p.get_height()/len(df)), (p.get_x()+ p.get_width() / 2 - 0.05, p.get_y() + p.get_height()),\n",
    "                    color= 'black')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df[(df['reviews_doRecommend'].isnull())]['reviews_rating'].value_counts().plot.bar()\n",
    "plt.xticks(size=12,rotation = 45)\n",
    "plt.xlabel('User Recommendation when not purchased',size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel('count', size=12)\n",
    "plt.title('User Recommendation when not purchased')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are only 9% data missing in the reviews_doRecommend column. We will assume that if the people are happy about the product, they will recommend the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZokd4h_Ijtc"
   },
   "outputs": [],
   "source": [
    "df['reviews_doRecommend']=df['reviews_rating'].apply(lambda x: True if x>=3 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbRfMPLjSw2w",
    "outputId": "7f32bdb2-9045-40df-fccc-bb049d0e6b08"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4Qa8NDfSsmH"
   },
   "source": [
    "Only Manufacturer, review date and review title have null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have the brand and the name of the product. so we can find the product with this. We will replace the null value is 'unknown' word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXSTZi-GZZO3"
   },
   "outputs": [],
   "source": [
    "df['manufacturer']=df['manufacturer'].replace(np.NaN,'Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets check the review date/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfa6cNT8mBsN",
    "outputId": "0b4b75f2-ed38-4c1e-d750-a7b97b7dc4a5"
   },
   "outputs": [],
   "source": [
    "df['reviews_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The field 'reviews date' is not in the datetime format. so lets first convert it to date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FtEgOrFmYrF"
   },
   "outputs": [],
   "source": [
    "df['reviews_date'] = pd.to_datetime(df['reviews_date'],errors='coerce').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMur_ElCpcR2",
    "outputId": "0843780b-f5d1-4fee-9621-1a0248efd2b6"
   },
   "outputs": [],
   "source": [
    "df['reviews_date'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To replace the null value, lets add max used date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUnF43MSpdfn"
   },
   "outputs": [],
   "source": [
    "df['reviews_date']=df['reviews_date'].replace(np.NaN,df['reviews_date'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jc9r4xHhmqRn"
   },
   "outputs": [],
   "source": [
    "df['review_yr']=[dt.year for dt in (df['reviews_date'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "WxyOgtT9p5ea",
    "outputId": "19628ffc-e70b-436a-90c3-dd675a549db8"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.distplot(df['review_yr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "165oJBgzSp6Z",
    "outputId": "a052f168-fd5c-46cf-96fe-61b4f04f3fc3"
   },
   "outputs": [],
   "source": [
    "df[df.duplicated(subset={\"id\",\"reviews_username\",\"brand\",\"categories\",\"name\"}, keep='first')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6_SpfmtWb4M"
   },
   "source": [
    "- There are 2349 rows of duplicate records for the same user and for the same product. Hence removing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UGX3ZryTgKl"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset={\"reviews_username\",\"brand\",\"categories\",\"name\"},keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Inpv4kVaVTfj",
    "outputId": "9b24e94b-c9d7-456d-b072-58981cc8a7fd"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRE6SdY3ZMF3",
    "outputId": "28f724ee-ebb4-472a-e5a1-c45812121bd2"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only reviews_title is null. Lets check the column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "2O1HUV3ezDYe",
    "outputId": "7104b0a5-b95b-4559-a852-bb98f79dc54a"
   },
   "outputs": [],
   "source": [
    "df[df.reviews_title.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Its just the title of the product is missing, lets replace it with brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZtoSj0-zRML"
   },
   "outputs": [],
   "source": [
    "df['reviews_title'] = np.where(~df['reviews_title'].isnull(),df['reviews_title'],df['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "oCRL8CKTzhTF",
    "outputId": "dfbd818a-3f66-4262-fe9c-a88fae2906b9"
   },
   "outputs": [],
   "source": [
    "df[df['reviews_title'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now no null values in the reviews_title. Lets take a random location in null value for review_title and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "pgjmuLRh0Gr2",
    "outputId": "7f8fefd7-4a8f-4cac-97f6-016a8b1fa900"
   },
   "outputs": [],
   "source": [
    "df.loc[[1239,]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the review_title is replaced with the brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kv5moZc0pvPb",
    "outputId": "e2a1cfca-9130-4e72-a492-997e78e7d773"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9B17kqM7ZUeq",
    "outputId": "2e6b4a2e-3639-493e-b3e9-05dab5777e22"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the null value is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will change the user sentiment to 0 and 1, o for Negative and 1 for positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "smW5mMJZrMnu",
    "outputId": "3ea3f791-4fe8-44a7-9298-f214d793723b"
   },
   "outputs": [],
   "source": [
    "df['user_sentiment']= df['user_sentiment'].apply(lambda x:1 if x=='Positive' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "mK1hCBb4sXnX",
    "outputId": "af8783fe-2d48-4f3e-d3dd-2f3a3dd206bb"
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=df,x='review_yr',y='reviews_rating',col='user_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the proper data cleaning, we can see that rating 1,2 are assigned for Negative sentiment and 3,4,5 are assigned to the positive user sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns required for the recommendations are username, rating, sentiment. Lets plot and verify the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "Pfddb47-pLER",
    "outputId": "638a6e84-b450-4ac6-b18c-a0164ca53f76"
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(data=df,values='reviews_username',columns='reviews_rating',\n",
    "               index=['user_sentiment'],\n",
    "               aggfunc='count').plot(kind='bar',figsize=(8,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that there is very less record in the negative. We should be using class imbalance techniques for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "yh_bZ5yGsk8b",
    "outputId": "b6ab7fe0-cb6a-4723-b1e4-d0b7cad2a4b7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,7)) \n",
    "sns.heatmap(df.corr(),annot = True,cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Awok0aGZXEfx",
    "outputId": "abbb370a-c41a-4ef0-e678-6da1ec63ace0"
   },
   "outputs": [],
   "source": [
    "# verifying reviews_title for the high rating\n",
    "df[(df['reviews_rating'].isin([3,4,5]) )]['reviews_title'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3lRg_0jXefY",
    "outputId": "90d8669f-27b7-48b1-ea63-4e9bdf787629"
   },
   "outputs": [],
   "source": [
    "# verifying reviews_title for the high rating\n",
    "df[(df['reviews_rating'].isin([1,2]))]['reviews_title'].unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like it is properly splited. Lets view in word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "jocKlx4IX1MS",
    "outputId": "f8dec5e4-2c01-4556-fd94-132264549eaa"
   },
   "outputs": [],
   "source": [
    "wordclouddisppointed = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stop_words,\n",
    "                min_font_size = 8,max_words=40).generate(str(df[(df['reviews_rating'].isin([1,2]))]['reviews_title'].unique()[:10]))\n",
    "wordcloudappreciation = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stop_words,\n",
    "                min_font_size = 8,max_words=40).generate(str(df[(df['reviews_rating'].isin([3,4,5]))]['reviews_title'].unique()[:10]))\n",
    "\n",
    "plt.figure(figsize = (7 ,7), facecolor = None)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloudappreciation)\n",
    "\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.title(\"Appreciation\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordclouddisppointed)\n",
    "\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.title(\"Disappointed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the Text preprocessing/ tfIdf vectorization, we need the review content and the user sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndcLAkBNX8cg"
   },
   "outputs": [],
   "source": [
    "df_TextPreprocessing = df[['reviews_text','reviews_title','reviews_rating','user_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP0fOMIVxDm4"
   },
   "outputs": [],
   "source": [
    "### We keep the title and text together are content\n",
    "df_TextPreprocessing['review_content'] = df_TextPreprocessing['reviews_title'] + \" \" +df_TextPreprocessing['reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "32_rnoIaxgV9",
    "outputId": "5a08a5fe-fa69-46cf-a142-2c0d4376ed2d"
   },
   "outputs": [],
   "source": [
    "### since title and text are already merged, we will remove that column\n",
    "df_TextPreprocessing.drop(['reviews_text','reviews_title'],axis=1,inplace=True)\n",
    "df_TextPreprocessing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "0epB8bWFuAjB",
    "outputId": "d9f98816-199c-4933-a822-5682926cccbd"
   },
   "outputs": [],
   "source": [
    "### Lets check whether we have not in positive also. we can see not commonly used in positive sentiment also like not dry etc.\n",
    "df_TextPreprocessing[df_TextPreprocessing['review_content'].str.contains(\"not|n\\'t\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets read the first positive comment with not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "ERRCESygucgy",
    "outputId": "d65ddac4-19bb-473c-bc7d-ae79adc37d35"
   },
   "outputs": [],
   "source": [
    "df_TextPreprocessing.loc[29992,'review_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets read the negative comment with not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "11RTldOvvwmU",
    "outputId": "6271e91f-fbbb-4871-f6be-ac5cf0972808"
   },
   "outputs": [],
   "source": [
    "df_TextPreprocessing.loc[7,'review_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPkD51Yixo3N"
   },
   "outputs": [],
   "source": [
    "# Function to clean the text and remove all the unnecessary elements like punctuations, numbers and other chars.\n",
    "def cleandata(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FeE-YCWwwzRZ",
    "outputId": "29a5e2ba-c441-4229-f8ff-583112f68535"
   },
   "outputs": [],
   "source": [
    "### Applying the text preprocessing step\n",
    "df_TextPreprocessing['clean_review'] = pd.DataFrame(df_TextPreprocessing.review_content.apply(lambda x: cleandata(x)))\n",
    "df_TextPreprocessing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets apply lemmatization in the clean text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ar8-mi4w_v1"
   },
   "outputs": [],
   "source": [
    "### Function to lemmatize the sentence\n",
    "def lemmatizer(text):        \n",
    "    sentence = [wordnet_lemmatizer.lemmatize(word) for word in word_tokenize(text) if not word in stop_words]\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lqIGPMjxCmG"
   },
   "outputs": [],
   "source": [
    "### Applying lemmatization for all the text in the dataframe\n",
    "df_TextPreprocessing['lemma_review'] =  df_TextPreprocessing['clean_review'].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "GE9uufA6xqBO",
    "outputId": "14e6057f-6355-424e-e8f0-4ea494f07eb0"
   },
   "outputs": [],
   "source": [
    "df_TextPreprocessing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "RoCu0pUtzuig",
    "outputId": "b2dd5a5e-7984-4922-dcf0-3b13d832f11e"
   },
   "outputs": [],
   "source": [
    "#### After lemmatization, lets check the most used words \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stop_words,\n",
    "                min_font_size = 8,max_words=40).generate(str(df_TextPreprocessing.lemma_review))\n",
    "\n",
    "print(wordcloud)\n",
    "plt.figure(figsize = (8 ,8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now Lets plot the Unigram, Bigram and Trigram words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIpPb6Akz3tU"
   },
   "outputs": [],
   "source": [
    "### Function to call any number of n-grams\n",
    "def get_top_n_gram(corpus, gram=None, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(gram, gram), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "cmjBVeq10Awj",
    "outputId": "68ec8e5c-5e13-4426-cf8d-be0762aaad54"
   },
   "outputs": [],
   "source": [
    "unigram_words = get_top_n_gram(df_TextPreprocessing.lemma_review,1, 30)\n",
    "unigram_df = pd.DataFrame(unigram_words[:10], columns = ['unigram' , 'count'])\n",
    "plt.figure(figsize = (15 ,6))\n",
    "sns.barplot(data = unigram_df, x='unigram', y= 'count')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(\"Top 10 Unigram words\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "mSsVFAxk0pp-",
    "outputId": "846cce08-359e-4319-f10d-8101e5f68293"
   },
   "outputs": [],
   "source": [
    "bigram_words = get_top_n_gram(df_TextPreprocessing.lemma_review,2, 30)\n",
    "bigram_df = pd.DataFrame(bigram_words[:10], columns = ['bigram' , 'count'])\n",
    "plt.figure(figsize = (10 ,6))\n",
    "sns.barplot(data = bigram_df, x='bigram', y= 'count')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(\"Top 10 Bigram words\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "SR3CgWTC1DdR",
    "outputId": "4db0f0e1-668e-4f28-843d-79dd18ca671f"
   },
   "outputs": [],
   "source": [
    "trigram_words = get_top_n_gram(df_TextPreprocessing.lemma_review,3, 30)\n",
    "trigram_df = pd.DataFrame(trigram_words[:10], columns = ['trigram' , 'count'])\n",
    "plt.figure(figsize = (10 ,6))\n",
    "sns.barplot(data = trigram_df, x='trigram', y= 'count')\n",
    "plt.xticks(rotation=70)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35ZtiUbloydW",
    "outputId": "b9831d33-1c94-42af-fbfc-9fcb80f49f6a"
   },
   "outputs": [],
   "source": [
    "(df['user_sentiment'].value_counts()/df['user_sentiment'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJbz2s2gsC8E"
   },
   "outputs": [],
   "source": [
    "#Initialise the TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english',max_df = 0.95,min_df = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xPock5wP2qig",
    "outputId": "4d55fb48-e849-43ed-cb93-2e2ec8217a22",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Viewing the features list\n",
    "dtm = tfidf.fit_transform(df_TextPreprocessing.lemma_review)\n",
    "pd.DataFrame(dtm.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will take only the lemma content and the corresponding user sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfkalL512wRk"
   },
   "outputs": [],
   "source": [
    "training_data= df_TextPreprocessing[['lemma_review','user_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCNlquaS3wmR",
    "outputId": "63094c20-9dda-4be3-82f8-9fdc4cbeefdb"
   },
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zuqqrka_32J9"
   },
   "outputs": [],
   "source": [
    "X = training_data.lemma_review\n",
    "y = training_data.user_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSXfRjnW36Se"
   },
   "outputs": [],
   "source": [
    "### splitting the data in xtrain and xtest\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the data using TfIdf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-b0TXhON4C24"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_transformer.fit(X_train)\n",
    "X_tfidf = tfidf_transformer.transform(X_train)\n",
    "X_testtfidf = tfidf_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_transformer, open(\"tfidfvec.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xpn-F5AB4KKJ"
   },
   "outputs": [],
   "source": [
    "X_train = X_tfidf\n",
    "X_test = X_testtfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbudsQZM4Q3L",
    "outputId": "ac57276b-a4a4-4048-8bfc-bdda86aaf769",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(F'ACC : {accuracy_score(y_test,y_pred)}')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is 95%\n",
    "- Recal value is not good\n",
    "- Lets veify few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9LMic-l4pu_",
    "outputId": "915f57f6-313d-45fc-cbba-540ba17788c9"
   },
   "outputs": [],
   "source": [
    "### Negative text verification\n",
    "texts = ['My husband and I bought this for some extra fun. We werevboth extremely disappointed. Especially for the price! Do not waste your money on this product. We felt nothing but a sticky mess from it.']\n",
    "\n",
    "text_features = tfidf_transformer.transform(texts)\n",
    "predictions = clf.predict(text_features)\n",
    "print(predictions[0])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Its wrongly classifyinf as positive statement. Its because, we have observed that there is less negative reocrds. We have trained the model with more positive records and less negative records. The model needs to be training more on negative records as well. Lets use some class imbalance techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T01XnjE45BbH",
    "outputId": "a60c7bee-7074-4d1b-d9e1-a01e170a796f"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "x_train_sm, y_train_sm = smote.fit_resample(X_train,y_train)\n",
    "print(\"The number of classes after SMOTE fit {}\".format(Counter(y_train_sm)))\n",
    "print(\"\");\n",
    "#Under Sampling\n",
    "ns = NearMiss(0.8)\n",
    "x_train_ns, y_train_ns = ns.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes after NearMiss fit {}\".format(Counter(y_train_ns)))\n",
    "print(\"\");\n",
    "\n",
    "os = RandomOverSampler(0.75)\n",
    "x_train_os, y_train_os = os.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes after RandomOverSampler fit {}\".format(Counter(y_train_os)))\n",
    "print(\"\");\n",
    "\n",
    "sm = SMOTETomek(0.75)\n",
    "x_train_smt, y_train_smt = sm.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes after SMOTETomek fit {}\".format(Counter(y_train_smt)))\n",
    "print(\"\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "905wC5QM5m6P",
    "outputId": "f803905d-7e6b-45c0-de99-ce127bbbc370"
   },
   "outputs": [],
   "source": [
    "y_train_smt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bie_xPOH50rK",
    "outputId": "0e28bb01-f045-42e9-bb87-0de7ce0a904b"
   },
   "outputs": [],
   "source": [
    "y_train_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again apply the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVgsp9cz53KL",
    "outputId": "d8ae246d-ab49-40c2-c15e-5dd9a57df141"
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(F'ACC : {accuracy_score(y_test,y_pred)}')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets verify with few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR77jd146KjN",
    "outputId": "4ff99deb-5ba5-4a31-ffd4-354598d61579"
   },
   "outputs": [],
   "source": [
    "### Negative comment\n",
    "texts = ['My husband and I bought this for some extra fun. We werevboth extremely disappointed. Especially for the price! Do not waste your money on this product. We felt nothing but a sticky mess from it.']\n",
    "\n",
    "text_features = tfidf_transformer.transform(texts)\n",
    "predictions = clf.predict(text_features)\n",
    "print(predictions[0])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUFsriuH6OfX",
    "outputId": "edd1f27d-77cd-4181-b410-9c7f71cd96bb"
   },
   "outputs": [],
   "source": [
    "### Positive comment with not\n",
    "texts = ['I love it amazing on my skin is so smooth nd not crack at all']\n",
    "\n",
    "text_features = tfidf_transformer.transform(texts)\n",
    "predictions = clf.predict(text_features)\n",
    "print(predictions[0])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZasqFlTm6WUM",
    "outputId": "3bd0ccb6-9907-42d6-c460-0eda12629656"
   },
   "outputs": [],
   "source": [
    "### Negative comment\n",
    "texts = ['I am disappointed']\n",
    "\n",
    "text_features = tfidf_transformer.transform(texts)\n",
    "predictions = clf.predict(text_features)\n",
    "print(predictions[0])\n",
    "print(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8DTbnOy6uPj",
    "outputId": "61c54318-ad63-4f4d-cfae-f43d3701da0c"
   },
   "outputs": [],
   "source": [
    "### Positive comment\n",
    "texts = ['Great product']\n",
    "\n",
    "text_features = tfidf_transformer.transform(texts)\n",
    "predictions = clf.predict(text_features)\n",
    "print(predictions[0])\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now its working properly. Lets build other models as well and check which model has high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After multiple runs with the grid search CV, placed only the hypertuned params which has the high accuracy.\n",
    "- I have removed all the gridsearch CV from this notebook to save some space and runtime of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0F03FupP7KAB"
   },
   "outputs": [],
   "source": [
    "### Few models from different classifier model\n",
    "\n",
    "dict_classifiers_selected = {    \n",
    "    \"Basic_LogisticRegression\":LogisticRegression(),\n",
    "    \"ClassBalance_LogisticRegression\": LogisticRegression(class_weight='balanced'),\n",
    "    \"DecisionTreeClassifier\" : DecisionTreeClassifier(max_depth=20, min_samples_leaf=5, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(max_depth=35, min_samples_leaf=5, n_jobs=-1,\n",
    "                       random_state=42),    \n",
    "    \"GradiantBoosting\": GradientBoostingClassifier(learning_rate=0.6, max_depth=2, n_estimators=200,\n",
    "                           subsample=0.9)\n",
    "    \n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qMR-xoA-gnq"
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "no_classifiers = len(dict_classifiers_selected.keys())\n",
    "\n",
    "def classify_and_score(xtrain,ytrain,xtest,ytest):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,11)), columns = ['classifier', 'train_score', 'test_score', 'Train Recall', 'Test Recall','Train Precision','Test Precision','Train F1','Test F1',\"ROC_AUC\", \"MCC\" ])\n",
    "    count = 0\n",
    "    \n",
    "    #ROC curve baseline\n",
    "    ns_probs = [0 for _ in range(len(ytest))]\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(ytest, ns_probs)\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "    \n",
    "    #Precision Recall curve baseline\n",
    "    baseline_model = sum(ytest == 1) / len(ytest)\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot([0, 1], [baseline_model, baseline_model], linestyle='--', label='Baseline model')\n",
    "\n",
    "        \n",
    "    for key, classifier in dict_classifiers_selected.items():\n",
    "        tmp = classifier.fit(xtrain, ytrain)\n",
    "        \n",
    "        y_train_predict = classifier.predict(xtrain)\n",
    "        y_test_predict = classifier.predict(xtest)\n",
    "    \n",
    "        #Precision Recall curve\n",
    "        probs_lr = classifier.predict_proba(xtest)[:, 1]\n",
    "        precision_lr, recall_lr, thresholds = precision_recall_curve(ytest, probs_lr)\n",
    "        auc_lr = auc(recall_lr, precision_lr)\n",
    "\n",
    "        fscore = (2 * precision_lr * recall_lr) / (precision_lr + recall_lr)\n",
    "        # locate the index of the largest f score\n",
    "        ix = argmax(fscore)\n",
    "        print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(recall_lr, precision_lr, label=f'AUC ${key} = {auc_lr:.2f}')\n",
    "        plt.scatter(recall_lr[ix], precision_lr[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'train_score'] = accuracy_score(ytrain,y_train_predict)\n",
    "        df_results.loc[count,'test_score'] = accuracy_score(ytest, y_test_predict)\n",
    "        df_results.loc[count,'Train Recall'] = recall_score(ytrain,y_train_predict,average='weighted')\n",
    "        df_results.loc[count,'Test Recall'] = recall_score(ytest,y_test_predict,average='weighted')        \n",
    "        df_results.loc[count,'Train Precision'] = precision_score(ytrain,y_train_predict,average='weighted')\n",
    "        df_results.loc[count,'Test Precision'] = precision_score(ytest,y_test_predict,average='weighted')\n",
    "        df_results.loc[count,'Train F1'] = f1_score(ytrain,y_train_predict,average='weighted')\n",
    "        df_results.loc[count,'Test F1'] = f1_score(ytest,y_test_predict,average='weighted')     \n",
    "\n",
    "        \n",
    "        mcc = matthews_corrcoef(ytest, y_test_predict)  \n",
    "        \n",
    "        #ROC Recall curve\n",
    "        fpr, tpr, thresholds = roc_curve(ytest, y_test_predict)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        \n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(fpr, tpr, marker='.', label=f'AUC ${key} = {roc_auc:.2f}')\n",
    "      \n",
    "\n",
    "        \n",
    "        df_results.loc[count,'ROC_AUC'] =   roc_auc     \n",
    "        df_results.loc[count,'MCC'] = mcc      \n",
    "        count+=1\n",
    "   \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('ROC Curv', size=20)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend();\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title('Precision-Recall Curve', size=20)\n",
    "    plt.xlabel('Recall', size=14)\n",
    "    plt.ylabel('Precision', size=14)\n",
    "    plt.legend();\n",
    "    \n",
    "    \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without any class imbalance checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H0Jg3-WX-1uw",
    "outputId": "7979bead-c8b6-42c7-a5c2-da28125bc440"
   },
   "outputs": [],
   "source": [
    "print(\"Label encoded data set\")\n",
    "print(\"-------------------------------------------\")\n",
    "res1 = classify_and_score(X_train, y_train,X_test, y_test)\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying smotek technique and checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uZIvSyqR-7E-",
    "outputId": "a1d1d554-9e3d-46eb-9259-ef1480b54a6a"
   },
   "outputs": [],
   "source": [
    "print(\"SMOTETomek on label encoder\")\n",
    "print(\"-------------------------------------------\")\n",
    "res2 = classify_and_score(x_train_smt,y_train_smt,X_test, y_test)\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying RandomOverSampler technique and checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UHxPuE84PRfI",
    "outputId": "9ff466cd-1dc6-4185-b24e-20d037b8738f"
   },
   "outputs": [],
   "source": [
    "print(\"RandomOverSampler on label encoder\")\n",
    "print(\"-------------------------------------------\")\n",
    "res3 = classify_and_score(x_train_os,y_train_os,X_test, y_test)\n",
    "res3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying smote technique and checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nk7PI3ckPs4_",
    "outputId": "7643d485-90b8-4bca-dc44-701d5192e2e4"
   },
   "outputs": [],
   "source": [
    "print(\"SMOTE on label encoder\")\n",
    "print(\"-------------------------------------------\")\n",
    "res4 = classify_and_score(x_train_sm,y_train_sm,X_test, y_test)\n",
    "res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yS9gSHdfBCT7",
    "outputId": "a5f75785-fbef-4fe6-c066-889d75b0a047",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##final_model = xgb.XGBClassifier(learning_rate=0.4, max_depth=6, n_estimators=500, subsample=0.9)\n",
    "\n",
    "##final_model.fit(x_train_smt,y_train_smt )\n",
    "\n",
    "##y_prob_test=final_model.predict_proba(X_test)\n",
    "##y_pred_test=final_model.predict(X_test)\n",
    "##print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(class_weight='balanced')\n",
    "final_model.fit(x_train_sm,y_train_sm)\n",
    "\n",
    "y_prob_test=final_model.predict_proba(X_test)\n",
    "y_pred_test=final_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZAVs_x-GeSi",
    "outputId": "339beff0-b2da-4ce8-cbf6-2a792bb8f151"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8o35FGpGviE",
    "outputId": "089def87-1818-4b31-a9bc-811adcbb0f7a"
   },
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_test)\n",
    "df_conf_mat = pd.DataFrame(conf_mat)\n",
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(df_conf_mat, annot=True,cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creatiing pickle of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0xm8DDf5cuf"
   },
   "outputs": [],
   "source": [
    "filename = 'LogisticClassifier_model.pkl'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r307VrxiFv9V"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will take only the required field for the sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = df[['id','brand', 'name', 'categories','reviews_text','reviews_title','reviews_rating','reviews_username','user_sentiment']]\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sentiment_df['reviews_content'] = sentiment_df['reviews_title'] + sentiment_df['reviews_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sentiment_df.drop(['reviews_title','reviews_text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sentiment_df['Items'] = sentiment_df['brand'] + \"_\"+ sentiment_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sentiment_df.drop(['brand','name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verifyting the Total ratings provided for the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.groupby('name')['reviews_rating'].count().reset_index().sort_values('reviews_rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that there are single rating as well. But we cannot remove this. This might be new products and might need user to try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item_ratedf = sentiment_df.groupby('name')['reviews_rating'].count().reset_index().sort_values('reviews_rating', ascending=False)\n",
    "Item_ratedf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the list of users and the number of ratings provided by the user/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.groupby('reviews_username')['reviews_rating'].count().reset_index().sort_values('reviews_rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Sentiment Analysis we need mainly the 'Id' of the product, 'rating' and 'username'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=sentiment_df[['id', 'reviews_rating', 'reviews_username']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- All the null values were removed before itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### creating train and test split\n",
    "train, test = train_test_split(ratings, test_size=0.30, random_state=31)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the train dataset into matrix format in which columns are products and the rows are user IDs with the values of the ratings provided by users..\n",
    "df_pivot = train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='id',\n",
    "    values='reviews_rating'\n",
    ").fillna(0)\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating dummy train & dummy test dataset**\n",
    "\n",
    "These dataset will be used for prediction\n",
    "\n",
    "In the process of building a recommendation system, we do not want to recommend a product that the user has already rated or in some cases has performed some action on it such as view, like, share or comment. To eliminate these products from the recommendation list, we need to take the help of a âdummy data setâ.\n",
    "\n",
    "* Dummy train will be used later for prediction of the products which has not been rated by the user. To ignore the products rated by the user, we will mark it as 0 during prediction. The products not rated by user is marked as 1 for prediction in dummy train dataset.\n",
    "\n",
    "* Dummy test will be used for evaluation. To evaluate, we will only make prediction on the products rated by the user. So, this is marked as 1. This is just opposite of dummy_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the train dataset into dummy_train\n",
    "dummy_train = train.copy()\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The products not rated by user is marked as 1 for prediction. \n",
    "dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dummy train dataset into matrix format.\n",
    "dummy_train = dummy_train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='id',\n",
    "    values='reviews_rating'\n",
    ").fillna(1)\n",
    "\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **User Based Similarity:**\n",
    "\n",
    "**Cosine Similarity:**\n",
    "* Cosine Similarity is a measurement that quantifies the similarity between two vectors [Which is Rating Vector in this case]\n",
    "\n",
    "**Adjusted Cosine Similarity:**\n",
    "* Adjusted cosine similarity is a modified version of vector-based similarity where we incorporate the fact that different users have different ratings schemes. In other words, some users might rate items highly in general, and others might give items lower ratings as a preference. To handle this nature from rating given by user , we subtract average ratings for each user from each user's rating for different movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Adjusted Cosine Similarity**\n",
    "\n",
    "Here, we are not removing the NaN values and calculating the mean only for the products rated by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the User Similarity Matrix using pairwise_distance function.\n",
    "user_correlation = 1 - pairwise_distances(df_pivot, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-product matrix.\n",
    "df_pivot = train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='id',\n",
    "    values='reviews_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising the rating of the movie for each user around 0 mean\n",
    "mean = np.nanmean(df_pivot, axis=1)\n",
    "df_subtracted = (df_pivot.T-mean).T\n",
    "df_subtracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subtracted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find cosine similarity:**\n",
    "\n",
    "Used pairwise distance to find similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the User Similarity Matrix using pairwise_distance function.\n",
    "user_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction - User User**\n",
    "\n",
    "Doing the prediction for the users which are positively related with other users, and not the users which are negatively related as we are interested in the users which are more similar to the current users. So, ignoring the correlation for values less than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the correlation for values less than 0.\n",
    "user_correlation[user_correlation<0]=0\n",
    "user_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating predicted by the user is the weighted sum of correlation with the product rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_ratings = np.dot(user_correlation, df_pivot.fillna(0))\n",
    "user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_final_rating contains predicted ratings for products\n",
    "user_final_rating = np.multiply(user_predicted_ratings,dummy_train)\n",
    "user_final_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the top 20 recommendation for the user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on esample User ID as input [bob,00sab00]\n",
    "#user_input = str(input(\"Enter your user name\"))\n",
    "user_input = str('00sab00') # for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended products for the selected user based on ratings\n",
    "out_recommendation = user_final_rating.loc[user_input].sort_values(ascending=False)[:20]\n",
    "out_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "pickle.dump(user_final_rating.astype('float32'), open('user_final_rating.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the common users of test and train dataset.\n",
    "common = test[test.reviews_username.isin(train.reviews_username)]\n",
    "common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into the user-product matrix.\n",
    "common_user_based_matrix = common.pivot_table(index='reviews_username', columns='id', \n",
    "                                              values='reviews_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the user_correlation matrix into dataframe.\n",
    "user_correlation_df = pd.DataFrame(user_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df['reviews_username'] = df_subtracted.index\n",
    "user_correlation_df.set_index('reviews_username',inplace=True)\n",
    "user_correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.reviews_username.tolist()\n",
    "\n",
    "user_correlation_df.columns = df_subtracted.index.tolist()\n",
    "user_correlation_df_1 =  user_correlation_df[user_correlation_df.index.isin(list_name)]\n",
    "user_correlation_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3 = user_correlation_df_2.T\n",
    "user_correlation_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_correlation_df_3[user_correlation_df_3<0]=0\n",
    "\n",
    "common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))\n",
    "common_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "\n",
    "dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "\n",
    "dummy_test = dummy_test.pivot_table(index='reviews_username', columns='id', values='reviews_rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_predicted_ratings = np.multiply(common_user_predicted_ratings,dummy_test)\n",
    "common_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find RMSE(Root Mean Square Error) - User User:**\n",
    "\n",
    "Calculating the RMSE for only the products rated by user. For RMSE, normalising the rating to (1,5) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = common_user_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='reviews_username', columns='id', values='reviews_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_user = round((sum(sum((common_ - y )**2))/total_non_nan)**0.5,2)\n",
    "print(rmse_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Item Based Similarity:**\n",
    "\n",
    "**Using Item similarity**\n",
    "* Taking the transpose of the rating matrix to normalize the rating around the mean for different product ID. In the user based similarity, we had taken mean for each user instead of each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take transpose of user based df\n",
    "df_pivot = train.pivot_table(\n",
    "    index='reviews_username',\n",
    "    columns='id',\n",
    "    values='reviews_rating'\n",
    ").T\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the product rating for each product for using the Adujsted Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.nanmean(df_pivot, axis=1)\n",
    "df_subtracted = (df_pivot.T-mean).T\n",
    "df_subtracted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the cosine similarity using pairwise distances approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Similarity Matrix\n",
    "item_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
    "item_correlation[np.isnan(item_correlation)] = 0\n",
    "print(item_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the correlation only for which the value is greater than 0. (Positively correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation[item_correlation<0]=0\n",
    "item_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction - Item Item**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predicted_ratings = np.dot((df_pivot.fillna(0).T),item_correlation)\n",
    "item_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the rating only for the products not rated by the user for recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_final_rating = np.multiply(item_predicted_ratings,dummy_train)\n",
    "item_final_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the top 20 recommendation for the user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the user ID as input [bob,00sab00]\n",
    "#user_input = str(input(\"Enter your user name\"))\n",
    "user_input = str('00sab00') # for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommending the Top 5 products to the user.\n",
    "d = item_final_rating.loc[user_input].sort_values(ascending=False)[0:20]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation - Item Item**\n",
    "\n",
    "Evaluation will we same as you have seen above for the prediction. The only difference being, you will evaluate for the products already rated by the user insead of predicting it for the products not rated by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common =  test[test.id.isin(train.id)]\n",
    "common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_based_matrix = common.pivot_table(index='reviews_username', columns='id', values='reviews_rating').T\n",
    "common_item_based_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df = pd.DataFrame(item_correlation)\n",
    "item_correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df['id'] = df_subtracted.index\n",
    "item_correlation_df.set_index('id',inplace=True)\n",
    "item_correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df.columns = df_subtracted.index.tolist()\n",
    "\n",
    "item_correlation_df_1 =  item_correlation_df[item_correlation_df.index.isin(list_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df_2 = item_correlation_df_1.T[item_correlation_df_1.T.index.isin(list_name)]\n",
    "\n",
    "item_correlation_df_3 = item_correlation_df_2.T\n",
    "item_correlation_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_correlation_df_3[item_correlation_df_3<0]=0\n",
    "\n",
    "common_item_predicted_ratings = np.dot(item_correlation_df_3, common_item_based_matrix.fillna(0))\n",
    "common_item_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy test will be used for evaluation. To evaluate, we will only make prediction on the products rated by the user. So, this is marked as 1. This is just opposite of dummy_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "dummy_test = dummy_test.pivot_table(index='reviews_username', columns='id', values='reviews_rating').T.fillna(0)\n",
    "common_item_predicted_ratings = np.multiply(common_item_predicted_ratings,dummy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ = common.pivot_table(index='reviews_username', columns='id', values='reviews_rating').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find RMSE(Root Mean Square Error) - Item Item:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = common_item_predicted_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_item = round((sum(sum((common_ - y )**2))/total_non_nan)**0.5,2)\n",
    "print(rmse_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendation system for Product:**\n",
    "- Based on RMSE value, the selected recommendation system approach should be based on User-User based recommendation system because of lesser RMSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recommendation of Top 20 Products to a Specified User:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all pkl files\n",
    "tfidf_model = pickle.load(open('tfidfvec.pkl', 'rb'))\n",
    "user_based_recomm_model = pickle.load(open('user_final_rating.pkl', 'rb'))\n",
    "LR_sentiment_model = pickle.load(open('LogisticClassifier_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter sample user name\n",
    "user = str('00sab00')  # for e.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend top 20 products\n",
    "user_top20 = user_based_recomm_model.loc[user].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_top20 = pd.DataFrame(user_top20)  #.to_records())\n",
    "user_top20.reset_index(inplace = True)\n",
    "user_top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge top 20 products and its reviews\n",
    "\n",
    "top20_products_setiment = pd.merge(user_top20,sentiment_df,on = ['id'])\n",
    "top20_products_setiment.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to feature\n",
    "tfidf_model1 = pickle.load(open('tfidfvec.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_products_tfidf = tfidf_model1.transform(top20_products_setiment['reviews_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "top20_products_pred = LR_sentiment_model.predict(top20_products_tfidf)\n",
    "top20_products_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_products_setiment['top20_products_pred']=top20_products_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_products_setiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "senti_score is given by the percentage of positive reviews to the total reviews for each products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_score = top20_products_setiment.groupby(['name'])['top20_products_pred'].agg(['sum','count']).reset_index()\n",
    "senti_score['percent'] = round((100*senti_score['sum'] / senti_score['count']),2)\n",
    "senti_score.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Top 5 best products:**\n",
    "\n",
    "**Top 5 best products based on sentiment score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_score = senti_score.sort_values(by='percent',ascending=False)\n",
    "senti_score.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "senti_score['name'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CapstoneProject-Trial2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
